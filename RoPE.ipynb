{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9262ce8-5e19-48ec-9327-992d321b3b21",
   "metadata": {},
   "source": [
    "# Rotary PE\n",
    "This notebook is the implementation of [RoFormer]\n",
    "https://arxiv.org/pdf/2104.09864v5\n",
    "\n",
    "This implementation assumes d_model as embedding dimension for a single head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b676f183-ee3a-4999-9f3a-96148116b7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7297d7b4-bca8-4c84-bc21-c6b3db7eb03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size=4  #also called as context window or seq length\n",
    "d_model=8      # embedding dimension\n",
    "batch_size=4\n",
    "num_heads=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5cbdb81d-0c51-4981-b17e-394fbd4d2925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [3]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculating sinusoidal positition\n",
    "positions=torch.arange(block_size)[:,np.newaxis] # adds dimension \n",
    "positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d4b50b52-59c1-4408-b4c2-59d46556db30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# = {θi = 10000−2(i−1)/d, i ∈ [1, 2, ..., d/2]}. \n",
    "assert d_model%2==0\n",
    "i=torch.arange(1,d_model//2+1)\n",
    "exp_term=2*(i-1)/d_model\n",
    "theta=100000**(-exp_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f643f2d1-f756-4129-9104-de19ad33e30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_emb=np.zeros([block_size,d_model])\n",
    "pos_emb[:,0::2]=torch.cos(positions*theta)\n",
    "pos_emb[:,1::2]=torch.sin(positions*theta)\n",
    "pos_emb=pos_emb[np.newaxis,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6cd07718-19f7-4c9e-a9ea-8c37a617bfc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4, 8)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_emb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e9cada-f61c-413b-bc63-38dfcbb99cce",
   "metadata": {},
   "source": [
    "# Implementation of 3.4.2 from RoFormer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a68d7740-293e-47d0-944c-51f80efc265a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1.00000000e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "    1.00000000e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00]\n",
      "  [ 5.40302277e-01  8.41470957e-01  9.98419285e-01  5.62044978e-02\n",
      "    9.99994993e-01  3.16227227e-03  1.00000000e+00  1.77827940e-04]\n",
      "  [-4.16146845e-01  9.09297407e-01  9.93682086e-01  1.12231314e-01\n",
      "    9.99979973e-01  6.32451288e-03  9.99999940e-01  3.55655880e-04]\n",
      "  [-9.89992499e-01  1.41120002e-01  9.85803485e-01  1.67903304e-01\n",
      "    9.99954998e-01  9.48669016e-03  9.99999881e-01  5.33483806e-04]]]\n",
      "cosine tf.Tensor(\n",
      "[[[0.54030228 0.54030228 0.99841928 0.99841928 0.99999499 0.99999499\n",
      "   1.         1.        ]]], shape=(1, 1, 8), dtype=float64)\n",
      "sine tf.Tensor(\n",
      "[[[8.41470957e-01 8.41470957e-01 5.62044978e-02 5.62044978e-02\n",
      "   3.16227227e-03 3.16227227e-03 1.77827940e-04 1.77827940e-04]]], shape=(1, 1, 8), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "qw=torch.randn(batch_size,block_size,num_heads,d_model)#qw is token_embedding for single head\n",
    "cosine_term=tf.repeat(pos_emb[...,None,0::2],repeats=2,axis=-1)# None is to add extra dimension for broadcasting \n",
    "sine_term=tf.repeat(pos_emb[...,None,1::2],repeats=2,axis=-1)\n",
    "print(pos_emb)\n",
    "print('cosine',cosine_term[:,1,:,:])\n",
    "print('sine',sine_term[:,1,:,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "0d68d2d1-e1e9-4ab7-8298-3412641c87af",
   "metadata": {},
   "outputs": [],
   "source": [
    "qw2=torch.stack([-qw[...,1::2],qw[...,0::2]],axis=-1)\n",
    "qw2=qw2.view(qw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "94a4b902-edf8-45aa-8368-19c940e220d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.3123, -0.2228,  1.2253, -0.1009, -0.6112, -0.5076,  0.2906,  0.5408])\n",
      "tensor([ 0.2228,  0.3123,  0.1009,  1.2253,  0.5076, -0.6112, -0.5408,  0.2906])\n"
     ]
    }
   ],
   "source": [
    "print(qw[1,1,1,:])# this is matrix of (x1,x2,..) which is multiplied to cosine_term\n",
    "print(qw2[1,1,1,:])# this is matrix of (-x2,x1,..) which is multiplied to sine_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a8916b9e-54c9-4adc-b171-75ca3bfd1e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "qw=qw*cosine_term+qw2*sine_term"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
